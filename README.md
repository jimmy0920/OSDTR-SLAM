# Object Shape Differentiation and Texture Rendering for Neural Implicit SLAM
## Abstract
Neural implicit SLAM combines traditional SLAM image tracking technology with NeRF-based scene reconstruction, achieving impressive reconstruction results. However, existing methods face two challenges: (1) the difficulty of distinguishing geometric shapes; (2) texture rendering in complex scenes. The former is hindered by incomplete depth maps and random pixel sampling, resulting in a lack of constraints on the reconstructed object shapes in neural implicit SLAM. The latter issue arises from the uncertainties of traditional volume rendering methods and the drift in estimated poses, leading to blurred texture rendering between similar objects. Therefore, we propose a novel neural implicit SLAM framework that utilizes gradient and depth priors, which can enhance the reconstruction of object shape structures and texture rendering effects. For the first challenge, we introduce a new pixel sampling strategy focused on object shapes, which enhances the geometric expression of objects by strengthening the constraints on object edge shapes. For the second challenge, we propose an Î±-composition rendering method guided by depth maps, coupled with a new keyframe selection method for accurate pose estimation, to achieve realistic rendering between objects. Our method has been validated on datasets such as Replica and ScanNet, effectively improving the shape recognition of objects with similar textures in NeRF-based SLAM and enhancing the accuracy of texture rendering in scenes.

![](https://github.com/jimmy0920/OSDTR-SLAM/blob/main/framework.jpg)

Coming soon...
